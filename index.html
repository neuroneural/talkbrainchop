<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <link href="css/fontawesome-free-6.2.1-web/css/all.css" rel="stylesheet">

  <script src="lib/colorbrewer.v1.min.js" charset="utf-8"></script>
  <script src="lib/colorStringStandalone.js" charset="utf-8"></script>
  <script type="text/javascript" src="lib/jquery-2.2.4.min.js"></script>
  <!-- Load d3.js -->
  <script src="https://d3js.org/d3.v7.js"></script>

  <title>Brainchop Presentation</title>

  <meta name="description" content="A presentation about Brainchop">
  <meta name="author" content="Sergey M Plis">

  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">



  <link rel="stylesheet" href="dist/reset.css">
  <link rel="stylesheet" href="dist/reveal.css">
  <!-- Code syntax highlighting -->
  <link rel="stylesheet" href="plugin/highlight/atom-one-light.css" id="highlight-theme">
  <!-- <link rel="stylesheet" href="lib/css/zenburn.css"> -->
  <link rel="stylesheet" href="css/custom.css">
  <link rel="stylesheet" href="dist/theme/aml.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement('link');
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.scss';
    document.getElementsByTagName('head')[0].appendChild(link);
  </script>


</head>


<body>
  <div class="reveal">
    <!-- In between the <div="reveal"> and the <div class="slides">-->
    <!-- <header style="position: absolute; top: 10px; left: 100px; z-index: 500; font-size:100px;background-color: rgba(0,0,0,0); text-align: center !important"></header>  -->
    <!-- In between the <div="reveal"> and the <div class="slides">-->
    <!-- Any section element inside of this container is displayed as a slide #93a1a1 -->
    <div class="slides">
      <section>
        <section>
          <p>
          <h2 style="color: #000000">Brainchop and zero-footprint AI</h2>
          <div class="center">
            <img style="bottom=0; width=100%; box-shadow: 0px 0px 0px
                                rgba(150, 150, 255,0.8);
                                border:0;" width="60%" src="figures/TReNDS_logo_light.png" alt="IJCNN team">
          </div>
          <div style="color: #000000">
            Sergey Plis
          </div>
          <p>
            <img style="border:0; box-shadow: 0px 0px 0px;" width="200" src="figures/GSU.png" alt="logo">
            <img style="border:0; box-shadow: 0px 0px 0px
                                rgba(150, 150, 255, 0.8);" height="100" src="figures/neuroneural_logo.png"
              alt="Neuroneural">
        </section>
      </section>
      <section>
        <section>
          <h1>Motivation</h1>
        </section>
        <section data-background="figures/automation.jpg" data-vertical-align-top>
          <h2>The Age of AI</h2>
        </section>
        <section>
          <h2>publications, models, tools</h2>
          <h3 class="fragment">Abundance, scarcity, absence</h3>

          <blockquote style="background-color: #93a1a1; color: #fdf6e3; font-size: 36px; width: 100%;" class="fragment">
            Only 40% of radiology AI studies shared models; deep learning models showed the lowest availability (11.5%)
          </blockquote>
          <div class="slide-footer">
            Lee, T., Lee, J.H., Yoon, S.H., Park, S.H. and Kim, H., 2025. Availability and transparency of artificial
            intelligence models in radiology: a meta-research study. European Radiology, pp.1-12.
          </div>
        </section>
        <section>
          <row>
            <col50>
              <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8);" width="100%" class="fragment zoom-in"
                src="figures/sharing_models_publications.png" alt="github stars">
            </col50>
            <col50>
              <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8);" width="100%" class="fragment zoom-in" src="figures/nninteractive_readme.png"
                alt="github stars">
            </col50>
          </row>
          <div class="slide-footer">
            Lee, T., Lee, J.H., Yoon, S.H., Park, S.H. and Kim, H., 2025. Availability and transparency of artificial
            intelligence models in radiology: a meta-research study. European Radiology, pp.1-12.
          </div>
        </section>
        <section>
          <h2>Scaling laws gone awry</h2>
          <row>
            <col50>
              <ul style="font-size: 32px;">
                <li class="fragment roll-in" data-fragment-index="0"> NVIDIA GPU requirement
                <li class="fragment roll-in" data-fragment-index="1"> Larger models are always better
                <li class="fragment roll-in" data-fragment-index="2"> There are plenty of resources in the cloud
                <li class="fragment roll-in" data-fragment-index="3"> We just need larger cloud/data-center
                <li class="fragment roll-in" data-fragment-index="4"> And a nuclear reactor to power it (not a joke)
              </ul>
            </col50>
            <col50>
              <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8);" width="100%" class="fragment zoom-in" data-fragment-index="4"
                src="figures/nuclear_GPU.png" alt="github stars">
            </col50>
          </row>
        </section>
        <section>
          <h3>Privacy does matter</h3>
          <row>
            <col50>
              <ul style="font-size: 32px;">
                <li class="fragment roll-in"> Not all data can be transferred to the cloud
                <li class="fragment roll-in"> For ethical and legal reasons
                <li class="fragment roll-in"> To protect the trust of the users
                <li class="fragment roll-in"> For technical or administrative reasons
                <li class="fragment roll-in"> <em>And even when it is possible obtaining all permissions takes skill and
                    time</em>
              </ul>
            </col50>
            <col50>
              <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8);" width="100%" src="figures/Richard_Stallman_St.jpg" alt="github stars">
            </col50>
          </row>
        </section>
        <section>

          <blockquote style="background-color: #93a1a1; color: #fdf6e3; font-size: 36px; width: 100%;">
            A good result today is better than a perfect result tomorrow
          </blockquote>
        </section>
        <section>
          <h3>Skill issue</h3>
          <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8); margin-top: -20px;" width="40%" src="figures/average_familiarity_2x.png"
            alt="github stars">


          <div class="slide-footer">
            https://xkcd.com/2501/
          </div>
        </section>
        <section>
          <h2>Our Goal</h2>
          <ul>
            <li class="fragment roll-in"> AI models with top performance for regular users
            <li class="fragment roll-in"> w/ Minimal (preferably zero) installation burden
          </ul>
        </section>
      </section>
      <section>
        <section>
          <h1>Brainchop.org</h1>
        </section>
        <section data-background-iframe="figures/brainchop13_short.mp4">
        </section>

        <section data-background="figures/niivue_webpage.png">
          <div id="header-right" style="margin-right: -100px; margin-top: -300px">
            <img src="figures/ChrisRorden.png" alt="Chris Rorden"
              style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-bottom: -5%" width="160px">
            <div style="font-size:10pt;">Chris Rorden</div>
          </div>
          <div id="header-left" style="margin-right: -100px; margin-top: -300px">
            <img src="figures/TaylorHanayik.jpeg" alt="Taylor Hanayik"
              style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-bottom: -5%" width="160px">
            <div style="font-size:10pt;">Taylor Hanayik</div>
          </div>
        </section>

        <section data-vertical-align-top
          data-background-video="https://github.com/neuroneural/brainchop/releases/download/v4.1.0/Brainchop_overhaul.mp4"
          data-background-video-loop data-background-video-muted>
          <img style="border:0; box-shadow: 0px 10px 10px
                                    rgba(150, 150, 150,
                                    0.8);" width="70%" class="fragment zoom-in" src="figures/brainchop_interface.svg"
            alt="github stars">

          <div class="slide-footer" style="font-size:8pt;">
            Plis SM, Masoud M, Hu F, Hanayik T, Ghosh SS, Drake C, Newman-Norlund R, Rorden C. Brainchop: Providing an
            edge ecosystem for deployment of neuroimaging artificial intelligence models. Aperture neuro. <b>2024 Sep
              5</b>;4:10-52294.
          </div>
        </section>

        <section data-vertical-align-top data-background-size="contain"
          data-background="figures/brainchop_users_map.png">
          <h3>Judging adoption by <i class="fas fa-star"></i> <i class="fas fa-star"></i> <i class="fas fa-star"></i> <i
              class="fas fa-star"></i> <i class="fas fa-star"></i> on <i class="fab fa-github"></i></h3>
          <img style="border:0; box-shadow: 0px 10px 10px
                        rgba(100, 100, 100,
                        0.8); margin-top: 40%; margin-left: 40%;" width="40%" src="figures/brainchop_github_stars.png"
            alt="github stars">

        </section>

        <section>
          <a href="https://brainchop.org">brainchop.org</a>
        </section>
      </section>
      <section>
        <section>
          <h1><i class="fas fa-terminal"></i> Brainchop </h1>
        </section>
        <section data-background-iframe="https://deep-mi.org/FastSurfer/dev/overview/INSTALL.html"></section>
        <section>
          <div style="display: flex; justify-content: center;">
            <pre style="background: #000; color: #0f0; padding: 15px 25px;
                border-radius: 8px; font-family: monospace;
                font-size: 1.2em; text-align: left;">
      <code>$ pip install brainchop</code>
    </pre>
          </div>
        </section>
        <section data-vertical-align-top data-background-size="cover" data-background="figures/modern_terminal.png">
          <h3>Brainchop for the most elegant UI</h3>
          <img style="border:0; box-shadow: 0px 0px 0px
                                        rgba(150, 150, 255,
                                        0.8); margin-top: 1%; margin-left: -120%;" width="40%"
            class="fragment current-fragment fade-right" src="figures/brainchop_terminal_help.png" alt="github stars">
          <img style="border:0; box-shadow: 0px 0px 0px
                                        rgba(150, 150, 255,
                                        0.8); margin-left: 30%; margin-top: 1%; margin-right: -120%;" width="40%"
            class="fragment fade-left" src="figures/docker_logo_old.svg" alt="github stars">
        </section>
      </section>
      <section>
        <section>
          <h1>Under the hood</h1>
        </section>
        <section>
          <h3>pip install mindfultensors</h3>

          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-top: 0px" width="100%"
            src="figures/mongodb_logo.png" alt="mongo">
        </section>

        <section>
          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-top: -100px" width="100%"
            src="figures/Synth_generation_overview.png" alt="Synth Generation">
          <div class='slide-footer'>
            SynthSeg: Segmentation of brain MRI scans of any contrast and resolution without retraining
            B. Billot, D.N. Greve, O. Puonti, A. Thielscher, K. Van Leemput, B. Fischl, A.V. Dalca, J.E. Iglesias
            Medical Image Analysis (2023)
            <a href="https://github.com/BBillot/SynthSeg">SynthSeg github</a>
          </div>
        </section>

        <section>
          <h2>SynthStrip</h2>
          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1);" width="120%"
            src="figures/SynthStrip_example.png" alt="Synth Strip Example">
          <div class='slide-footer'>
            SynthStrip: Skull-Stripping for Any Brain Image
            Andrew Hoopes, Jocelyn S. Mora, Adrian V. Dalca, Bruce Fischl, Malte Hoffmann NeuroImage 260, 2022, 119474
            https://doi.org/10.1016/j.neuroimage.2022.119474
            <a href="https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/">SynthStrip page</a>
          </div>
        </section>

        <section>
          <h2>The Catch: Training takes a week</h2>
          GPU utilization
          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1);" width="100%"
            src="figures/SynthSeg_utilization.png" alt="synthseg training">
        </section>

        <section>
          <h2>Decouple training and generation</h2>
          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1);" width="60%"
            src="figures/differential_wirehead.gif" alt="differential">
        </section>

        <section>
          <div id="header-right" style="margin-right: -100px; margin-top: -20px">
            <img src="figures/Mike.png" alt="Mike Doan"
              style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-bottom: -5%" width="160px">
            <div style="font-size:10pt;">Mike Doan</div>
          </div>

          <h3>really Decouple training and generation</h3>
          <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-top: -50px;" width="100%"
            src="figures/wirehead_poster.png" alt="wirehead">
        </section>

        <section data-fullscreen>
          <div id="header-left" style="margin-top: 100px; margin-left: 50px;">
            <img style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); " width="130"
              src="figures/Olaf_Ronneberger_Portrait.jpg" alt="Ronneberger">
            <div style="font-size:14pt;">Olaf Ronneberger</div>
          </div>
          <h2>One U-shaped Network</h2>
          <h1 class="fragment roll-in">U-Net</h1>
          <img width="70%" style="margin-top: -260px;" src="figures/V-Net.png" alt="final model">
          <div class="slide-footer" style="margin-left: 200px;">
            <a href="https://arxiv.org/abs/1505.04597" target="_blank">
              Ronneberger et al. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015
            </a><br>
            <a href="https://arxiv.org/abs/1606.06650" target="_blank">
              Çiçek et al. 3D U-Net: learning dense volumetric segmentation from sparse annotation. MICCAI 2016
            </a>
          </div>
        </section>


        <section data-background="figures/unet_takeover.png" data-background-size="contain" data-vertical-align-top>
          <h2 style="margin-top: -30px; margin-left: -350px;">U-Net took over the world</h2>
        </section>

        <section>
          <h1>But there is a problem</h1>
          parameters and memory usage
        </section>

        <section data-fullscreen>
          <h2>Consider a small U-net</h2>
          <row>
            <col50>
              <img class="fragment roll-in" class="stretch" style="border:0; box-shadow: 0px 0px 0px
                                                rgba(150, 150, 255, 0.8);" width="100%" src="figures/unet_arc.png"
                alt="small U-Net">
            </col50>
            <col50>
              <img class="fragment roll-in" class="stretch" style="border:0; box-shadow: 0px 0px 0px
                                                    rgba(150, 150, 255, 0.8);" width="100%"
                src="figures/unet_table.png" alt="U-Net parameter table">
            </col50>
          </row>

          <div class='slide-footer'>
            Ronneberger et al. U-net: Convolutional networks
            for biomedical image segmentation. MICCAI 2015<br>
            Çiçek et al. 3D U-Net: learning dense volumetric
            segmentation from sparse annotation. MICCAI 2016
          </div>
        </section>

        <section data-fullscreen>
          <h2>Skip-connections need memory</h2>
          <img width="70%" style="margin-top: -70px;" src="figures/V-Net.png" alt="final model">
        </section>

        <section data-fullscreen>
          <h2>We could train on subcubes</h2>
          <img width="70%" style="margin-top: -70px;" src="figures/subvolume_prediction_pipeline.png" alt="final model">
        </section>

        <section>
          <h4>Full volume training and inference gives better accuracy</h4>
          <h4>but requires 80Gb GPU for training and more than 10Gb for inference</h4>
          <div class="slide-footer">
            Li, Y., Cui, J., Sheng, Y., Liang, X., Wang, J., Chang, E.I.C. and Xu, Y., 2021. Whole brain segmentation
            with full volume neural network. Computerized Medical Imaging and Graphics, 93, p.101991.</h5></br>
            Dorfner, F.J., Patel, J.B., Kalpathy-Cramer, J., Gerstner, E.R. and Bridge, C.P., 2025. A review of deep
            learning for brain tumor analysis in MRI. NPJ Precision Oncology, 9(1), p.2.
          </div>
        </section>

        <section>
          <div id="header-left" style="margin-left: -200px; z-index: 1500;">
            <img width="200px" style="margin-bottom: -5%;" src="figures/AlexFedorov.jpg" alt="Alex"><br>
            <small>Alex Fedorov</small>
          </div>
          <h2>MeshNet</h2>
          <row>
            <col40>
              <img class="fragment roll-in" class="stretch" style="border:0; box-shadow: 0px 0px 0px
                                                rgba(150, 150, 255, 0.8);" width="100%" src="figures/meshnet_arch.png"
                alt="MeshNet">
            </col40>
            <col60>
              <img class="fragment roll-in" class="stretch" style="border:0; box-shadow: 0px 0px 0px
                                                    rgba(150, 150, 255, 0.8);" width="100%" src="figures/mntable.png"
                alt="MeshNet parameter table">
              <ul style="font-size:30px;">
                <li class="fragment roll-in">72516 vs 23523355 U-Net parameters
                <li class="fragment roll-in">but that's for 21 channel MeshNet
                <li class="fragment roll-in">5 channel MeshNet is about 4x smaller
              </ul>
            </col60>
          </row>
          <div class='slide-footer' style="text-align: left;">
            Fedorov et al. End-to-end learning of brain tissue segmentation
            from imperfect labeling. IJCNN 2017
          </div>
        </section>
        <section>
          <h1>other Applications</h1>
        </section>
        <section data-vertical-align-top>
          <div id="header-right" style="margin-right: -130px; margin-top: 100px">
            <img src="figures/Armina.png" alt="Armina Fani"
              style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-bottom: -5%" width="160px">
            <div style="font-size:10pt;">Armina Fani</div>
          </div>

          <h2>Mindgrab</h2>
          <blockquote style="background-color: #eee8d5; font-size: 70%; margin-top: -10px; width: 70%">
            Robust Skull Stripping of Any Modality on Any Device
          </blockquote>
          <img class="stretch" style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 0.8);" width="150%"
            src="figures/mindgrab_simplified.png" alt="loop">
        </section>

        <section>
          <div id="header-right" style="margin-right: -100px; margin-top: 100px">
            <img src="figures/AlexFedorovEmory.png" alt="Alex Fedorov"
              style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 1); margin-bottom: -5%" width="120px">
            <div style="font-size:10pt;">Alex Fedorov</div>
          </div>
          <h3>Tumor Detection</h3>
          <img class="stretch" style="border:0; box-shadow: 0px 0px 0px rgba(150, 150, 255, 0.8);" width="160%"
            src="figures/pareto_front_winning.png" alt="loop">
        </section>

        <section>
          <h3>Other models (possibly)?</h3>
        </section>
        <section>
          <h4>The browser is not forgiving, but MeshNet is easy to train</h4>
        </section>

        <section data-vertical-align-top data-background="figures/tinygrad_page.png">
          <h3>pip install brainchop is much simpler though</h3>
          <h5>powered by</h5>
        </section>
      </section>
      <section>
        <section>
          <h1>The Future</h1>
        </section>
        <section>
          <h3>Faster personal devices, faster software</h3>
          <blockquote style="background-color: #eee8d5; font-size: 70%; margin-top: -10px; width: 70%">
            Personal devices are becoming much more powerful.
            <ul>
              <li> This means current problems get solved faster.
              <li> It also means complex "cloud" tasks are moving to the device itself.
              <li> <b>Goal</b>: We need to have the tools ready for users to take advantage of this shift.
            </ul>
          </blockquote>
        </section>
        <section>
          <h4>software is also becoming better: the upcoming WebGPU standard</h4>
        </section>
        <section data-vertical-align-top data-background-iframe="http://neuroneural.net/brainchop-test/"
          data-background-interactive>
          <h3 style="text-shadow: 4px 4px 4px #002b36; color: #93a1a1">upcoming WebGPU</h3>
        </section>

        <section data-vertical-align-top data-background-iframe="https://brainchop.org" data-background-interactive>
          <h3 style="text-shadow: 4px 4px 4px #002b36; color: #93a1a1">Interactive demo</h3>
          <div class='slide-footer'>
            <a href="https://brainchop.org">brainchop.org</a><br>
            <a href="https://github.com/neuroneural/brainchop">https://github.com/neuroneural/brainchop <i
                class="fab fa-github"></i></a>
          </div>
        </section>
      </section>
      <section>
        <h1>thank you!</h1>
      </section>
    </div>

  </div>

  <script src="dist/reveal.js"></script>

  <link rel="stylesheet" href="plugin/highlight/atom-one-light.css">
  <script src="plugin/highlight/highlight.js"></script>
  <script src="plugin/math/math.js"></script>
  <script src="plugin/chalkboard/plugin.js"></script>
  <script src="plugin/notes/notes.js"></script>
  <script src="plugin/zoom/zoom.js"></script>
  <script src="plugin/fullscreen/fullscreen.js"></script>
  <script src="plugin/verticator/verticator.js"></script>
  <script src="plugin/verticator/verticator.js"></script>
  <link rel="stylesheet" href="plugin/verticator/verticator.css">
  <script src="plugin/menu/menu.js"></script>

  <script>
    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration

    Reveal.initialize({
      // history: true,
      hash: true,
      margin: 0.01,
      minScale: 0.01,
      maxScale: 1.23,
      center: true,

      controls: false,
      keyboard: true,

      overview: true,
      transition: 'slide', // Transition style: none/fade/slide/convex/concave/zoom
      transitionSpeed: 'slow', // Transition speed: default/fast/slow
      menu: {
        themes: false,
        openSlideNumber: true,
        openButton: false,
      },

      chalkboard: {
        boardmarkerWidth: 1,
        chalkWidth: 2,
        chalkEffect: 1,
        toggleNotesButton: false,
        toggleChalkboardButton: false,
        slideWidth: Reveal.width,
        slideHeight: Reveal.height,
        // src: "chalkboards/chalkboard_em2.json",
        readOnly: false,
        theme: "blackboard",
        eraser: { src: "plugin/chalkboard/img/sponge.png", radius: 30 },
      },

      math: {
        mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
        config: 'TeX-AMS_SVG-full',
        // pass other options into `MathJax.Hub.Config()`
        TeX: {
          Macros: {
            RR: '\\mathbb{R}',
            PP: '\\mathbb{P}',
            EE: '\\mathbb{E}',
            NN: '\\mathbb{N}',
            vth: '\\vec{\\theta}',
            loss: '{\\cal l}',
            hclass: '{\\cal H}',
            CD: '{\\cal D}',
            def: '\\stackrel{\\text{def}}{=}',
            pag: ['\\text{pa}_{{\\cal G}^{#1}}(#2)}', 2],
            vec: ['\\boldsymbol{\\mathbf #1}', 1],
            set: ['\\left\\{#1 \\; : \\; #2\\right\\}', 2],
            bm: ['\\boldsymbol{\\mathbf #1}', 1],
            argmin: ['\\operatorname\{arg\\,min\\,\}'],
            argmax: ['\\operatorname\{arg\\,max\\,\}'],
            softmax: ['\\operatorname\{soft\\,max\\,\}'],
            prob: ["\\mbox{#1$\\left(#2\\right)$}", 2],
          },
          loader: { load: ['[tex]/color'] },
          extensions: ["color.js"],
          tex: { packages: { '[+]': ['color'] } },
          svg: {
            fontCache: 'global'
          }
        }
      },

      plugins: [Verticator, RevealMath, RevealChalkboard, RevealHighlight, RevealNotes, RevealZoom, RevealMenu],

    });

    Reveal.configure({ fragments: true }); // set false when developing to see everything at once
    Reveal.configure({ slideNumber: true });
    //Reveal.configure({ history: true });
    Reveal.configure({ slideNumber: 'c / t' });
    Reveal.addEventListener('darkside', function () {
      document.getElementById('theme').setAttribute('href', 'dist/theme/aml_dark.css');
    }, false);
    Reveal.addEventListener('brightside', function () {
      document.getElementById('theme').setAttribute('href', 'dist/theme/aml.css');
    }, false);

    // Listen for a fragment being shown
    Reveal.addEventListener('fragmentshown', function (event) {
      // Find all slides
      const allSlides = document.querySelectorAll('.slide');

      // Remove 'dim-background' from all slides first to ensure only the current slide is dimmed
      allSlides.forEach(slide => slide.classList.remove('dim-background'));

      // Find the closest ancestor slide of the shown fragment
      const currentSlide = Reveal.getCurrentSlide();
      // Check if the currentSlide has the 'special-dim' class
      if (currentSlide && currentSlide.getAttribute('data-state')) {
        console.log('target: ', currentSlide.getAttribute('data-state')); // Should be 'dimmed-slide' for this slide
        const toModify = event.fragment.closest('.slide');
        toModify.classList.add('dim-background');
        currentSlide.classList.add('dim-background');
      }
    });

    // Listen for a fragment being hidden and slide changes to remove the dimming effect where applicable
    ['fragmenthidden', 'slidechanged'].forEach(eventType => {
      Reveal.addEventListener(eventType, function () {
        // Find all slides and remove 'dim-background' class
        const slides = document.querySelectorAll('.slide');
        slides.forEach(slide => slide.classList.remove('dim-background'));
      });
    });



  </script>

  <style type="text/css">
    /* 1. Style header/footer <div> so they are positioned as desired. */
    #header-left {
      position: absolute;
      top: 0%;
      left: 0%;
    }

    #header-right {
      position: absolute;
      top: 0%;
      right: 0%;
    }

    #footer-left {
      position: absolute;
      bottom: 0%;
      left: 0%;
    }
  </style>

  <!-- // 2. Create hidden header/footer -->
  <div id="hidden" style="display:none;">
    <div id="header">
      <div id="header-left">
        <img style="border:0; box-shadow: 0px 0px 0px
			      rgba(150, 150, 255,0.8);" width="150" src="figures/BRAINCHOP.png" alt="brainchop">
      </div>
      <div id="header-right">
        <img style="border:0; box-shadow: 0px 0px 0px
			      rgba(150, 150, 255,0.8);" width="250" src="figures/TReNDS_logo_light.png" alt="TReNDS">
        <!-- <img style="border:0; box-shadow: 0px 0px 0px -->
        <!--             rgba(150, 150, 255, 0.8);" -->
        <!--      width="100" -->
        <!--      src="figures/neuroneural_logo.png" -->
        <!--      alt="Neuroneural"> -->
      </div>
      <div id="footer-left">
      </div>
    </div>
  </div>


  <script type="text/javascript">
    // 3. On Reveal.js ready event, copy header/footer <div> into each `.slide-background` <div>
    var header = $('#header').html();
    if (window.location.search.match(/print-pdf/gi)) {
      Reveal.addEventListener('ready', function (event) {
        $('.slide-background').append(header);
      });
    }
    else {
      $('div.reveal').append(header);
    }

  </script>

</body>

</html>